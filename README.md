# Word Sleuth Mysteries

## A Narrative Word-Finding Game

**Word Sleuth Mysteries** is an interactive word-finding game built with Phaser 3, designed to immerse players in a classic detective novel experience. Uncover hidden clues within intriguing narratives generated by a Large Language Model (LLM) and piece together the mystery!

## Features

* **Dynamic Story Generation:** Experience unique mysteries each round, with narratives crafted by an LLM based on carefully selected themes and "injected words" (clues).
* **Interactive Word Finding:** Draw lines across words in the narrative to highlight them and reveal hidden clues.
* **Categorized Clues:** Identify and collect specific types of clues: Objects, Places, People, and Events.
* **Engaging UI & Animations:** A sleek user interface and subtle animations enhance the gameplay experience.
* **Atmospheric Audio:** Immerse yourself in the detective world with background music.
* **Responsive Design:** Enjoy the game seamlessly across various screen sizes.

## How to Play

1.  **Read the Narrative:** A new mystery narrative will appear on screen. Read it carefully to understand the context and identify potential clues.
2.  **Find the Words:** The goal is to find the "injected words" (clues) related to an Object, Place, Person, and Event that are hidden within the narrative.
3.  **Draw to Select:** Click and drag your mouse (or touch and drag on mobile) to draw a line across words. If the words form one of the required clues and are in sequence, they will be highlighted and collected.
4.  **Complete the Round:** Successfully find all the required clue categories to complete the round.
5.  **New Mystery Awaits:** Once a round is complete, a new mystery and narrative will be generated.

## Technical Stack

* **Phaser 3:** The fast, free, and fun HTML5 Game Framework for desktop and mobile web browsers.
* **JavaScript (ES6+):** For game logic and interactive elements.
* **Large Language Model (LLM):** Used for dynamic narrative generation (currently configured for Ollama with `llama3:latest`).
* **HTML/CSS:** For basic structure and styling.

## Project Structure

```bash
.
├── index.html
├── package.json
├── package-lock.json
├── README.md
└── src
    ├── gameInit.js
    ├── data
    │   ├── audioAssets.js
    │   ├── gameConfig.js
    │   ├── imageAssets.js
    │   ├── initPrompt.js
    │   ├── injectedWords.js
    │   └── topics.js
    ├── managers
    │   ├── animationManager.js
    │   ├── backgroundManager.js
    │   ├── chatManager.js
    │   ├── roundManager.js
    │   ├── uiManager.js
    │   └── wordManager.js
    └── scenes
        ├── config.js
        └── mainScene.js

````

## Setup and Installation

To run this project locally, follow these steps:

1.  **Clone the repository:**
    ```bash
    git clone [https://github.com/umutarda/word-sleuth-mysteries.git](https://github.com/umutarda/word-sleuth-mysteries.git)
    cd word-sleuth-mysteries
    ```

2.  **Install Node.js dependencies:**
    This project likely uses npm (Node Package Manager) for its dependencies. Make sure you have Node.js and npm installed, then run:
    ```bash
    npm install
    ```

3.  **Install a Local LLM (Optional, but Recommended):**
    This game is designed to work with a local LLM for narrative generation.
    * **Install Ollama:** Follow the instructions on the [Ollama website](https://ollama.com/) to install Ollama on your system.
    * **Pull the `llama3:latest` model:**
        ```bash
        ollama pull llama3:latest
        ```
    * **Ensure Ollama is running:** Make sure the Ollama server is active, typically listening on `http://localhost:11434`.

4.  **Start the development server:**
    ```bash
    npm run dev
    ```
    The game will typically be available at `http://localhost:5173`. Check your console output for the exact address.
    
## Configuration

You can configure various aspects of the game in `src/data/gameConfig.js`:

```javascript
export const GAME_CONFIG = {
    UI_DEPTH: 10,
    MESSAGE_DEPTH: 7,
    WORD_DEPTH: 5,
    ROUND_TIME: 120, // Time in seconds per round 
    MODEL_NAME: "llama3:latest", // LLM model to use 
    LLM_API_URL: "http://localhost:11434/api/chat" // URL for your local LLM API 
}
````

Adjust `LLM_API_URL` if your Ollama instance is running on a different address or port.

## Contributing

Contributions are welcome\! If you have suggestions for improvements, new features, or bug fixes, please feel free to open an issue or submit a pull request.

## License

This project is open-source and available under the [MIT License](https://www.google.com/search?q=LICENSE).

-----

**Enjoy deciphering the mysteries\!**

```
